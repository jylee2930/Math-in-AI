{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPy1uk3e7bLIeNLOYHuOgJ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jylee2930/Math-in-AI/blob/main/%EB%B2%A1%ED%84%B0%EC%99%80_%EC%9E%90%EC%97%B0%EC%96%B4%EC%B2%98%EB%A6%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##ë²¡í„°ë¥¼ í™œìš©í•œ ìì—°ì–´ì²˜ë¦¬ ê³¼ì • ì‹¤ìŠµí•˜ê¸°"
      ],
      "metadata": {
        "id": "n3Ho_FnGZa5F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "metadata": {
        "id": "NeagkubncNPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ì£¼ì œ 1: ë‹¨ì–´ë¥¼ ë²¡í„°ë¡œ í‘œí˜„í•˜ê¸° (Word Embedding)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“š ì£¼ì œ 1: ë‹¨ì–´ë¥¼ ë²¡í„°ë¡œ í‘œí˜„í•˜ê¸°\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\"\"\n",
        "ğŸ’¡ ê°œë…:\n",
        "ë‹¨ì–´ë¥¼ ìˆ«ì ë¦¬ìŠ¤íŠ¸(ë²¡í„°)ë¡œ ë°”ê¾¸ë©´ ì»´í“¨í„°ê°€ ì´í•´í•  ìˆ˜ ìˆì–´ìš”!\n",
        "\n",
        "ì˜ˆì‹œ: í•™êµìƒí™œ ë‹¨ì–´ë“¤ì„ 2ì°¨ì› ë²¡í„°ë¡œ í‘œí˜„\n",
        "- [í•™ì—… ì ìˆ˜, ì¹œêµ¬ê´€ê³„ ì ìˆ˜]\n",
        "- ìˆ˜í•™: [10, 3]  â†’ í•™ì—…ì€ ë†’ì§€ë§Œ ì¹œêµ¬ê´€ê³„ëŠ” ì ìŒ\n",
        "- ì²´ìœ¡: [3, 10]  â†’ ì¹œêµ¬ê´€ê³„ëŠ” ë§ì§€ë§Œ í•™ì—…ì€ ì ìŒ\n",
        "- ì ì‹¬: [2, 9]   â†’ ì¹œêµ¬ë“¤ê³¼ í•¨ê»˜ ë¨¹ëŠ” ì‹œê°„\n",
        "\"\"\")\n",
        "\n",
        "# ì˜ˆì œ 1-1: ê°„ë‹¨í•œ ë‹¨ì–´ ë²¡í„° ë§Œë“¤ê¸°\n",
        "print(\"\\n[ì‹¤ìŠµ 1-1] í•™êµìƒí™œ ë‹¨ì–´ë¥¼ ë²¡í„°ë¡œ í‘œí˜„í•˜ê¸°\")\n",
        "\n",
        "# ë‹¨ì–´ë¥¼ ë²¡í„°ë¡œ í‘œí˜„ [í•™ì—…ì ìˆ˜, ì¹œêµ¬ê´€ê³„ì ìˆ˜]\n",
        "words = {\n",
        "    'ìˆ˜í•™': [10, 3],\n",
        "    'êµ­ì–´': [9, 4],\n",
        "    'ì²´ìœ¡': [3, 10],\n",
        "    'ìŒì•…': [5, 8],\n",
        "    'ì ì‹¬': [2, 9],\n",
        "    'ì‹œí—˜': [10, 2]\n",
        "}\n",
        "\n",
        "print(\"\\në‹¨ì–´ ë²¡í„°:\")\n",
        "for word, vector in words.items():\n",
        "    print(f\"  {word}: {vector}\")\n",
        "\n",
        "# ì‹œê°í™”\n",
        "plt.figure(figsize=(10, 8))\n",
        "for word, vector in words.items():\n",
        "    x, y = vector\n",
        "    plt.scatter(x, y, s=200, alpha=0.6)\n",
        "    plt.annotate(word, (x, y), fontsize=12, ha='center', va='bottom')\n",
        "\n",
        "plt.xlabel('í•™ì—… ê´€ë ¨ë„', fontsize=12)\n",
        "plt.ylabel('ì¹œêµ¬/ì‚¬íšŒì„± ê´€ë ¨ë„', fontsize=12)\n",
        "plt.title('ë‹¨ì–´ë¥¼ 2ì°¨ì› ë²¡í„°ë¡œ í‘œí˜„í•˜ê¸°', fontsize=14, fontweight='bold')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xlim(0, 12)\n",
        "plt.ylim(0, 12)\n",
        "plt.axhline(y=0, color='k', linewidth=0.5)\n",
        "plt.axvline(x=0, color='k', linewidth=0.5)\n",
        "plt.tight_layout()\n",
        "plt.savefig('word_vectors.png', dpi=300, bbox_inches='tight')\n",
        "print(\"\\nâœ… ê·¸ë˜í”„ ì €ì¥: word_vectors.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\"\\nğŸ“ ê´€ì°°:\")\n",
        "print(\"  - 'ìˆ˜í•™'ê³¼ 'ì‹œí—˜'ì€ í•™ì—… ìª½ì— ê°€ê¹Œì´ ìˆì–´ìš”\")\n",
        "print(\"  - 'ì²´ìœ¡'ê³¼ 'ì ì‹¬'ì€ ì¹œêµ¬ê´€ê³„ ìª½ì— ê°€ê¹Œì´ ìˆì–´ìš”\")\n",
        "print(\"  - ë¹„ìŠ·í•œ ì˜ë¯¸ì˜ ë‹¨ì–´ë“¤ì´ ê°€ê¹Œì´ ëª¨ì—¬ìˆì£ !\")"
      ],
      "metadata": {
        "id": "A2gjQGw_cTPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ì£¼ì œ 2: ë²¡í„° ì‚¬ì´ì˜ ê±°ë¦¬ ê³„ì‚° (ìœ í´ë¦¬ë“œ ê±°ë¦¬)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“ ì£¼ì œ 2: ë‹¨ì–´ ì‚¬ì´ì˜ ê±°ë¦¬ ì¬ê¸°\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\"\"\n",
        "ğŸ’¡ ê°œë…:\n",
        "ë‘ ë‹¨ì–´ê°€ ì–¼ë§ˆë‚˜ ë¹„ìŠ·í•œì§€ ë²¡í„° ì‚¬ì´ì˜ ê±°ë¦¬ë¡œ ì•Œ ìˆ˜ ìˆì–´ìš”!\n",
        "ê³ ë“±í•™êµ ìˆ˜í•™ ì‹œê°„ì— ë°°ìš´ 'ë‘ ì  ì‚¬ì´ì˜ ê±°ë¦¬ ê³µì‹'ì„ ì‚¬ìš©í•´ìš”.\n",
        "\n",
        "ê±°ë¦¬ ê³µì‹:\n",
        "d = âˆš[(xâ‚‚-xâ‚)Â² + (yâ‚‚-yâ‚)Â²]\n",
        "\n",
        "ê±°ë¦¬ê°€ ê°€ê¹Œìš°ë©´ â†’ ë¹„ìŠ·í•œ ì˜ë¯¸\n",
        "ê±°ë¦¬ê°€ ë©€ë©´ â†’ ë‹¤ë¥¸ ì˜ë¯¸\n",
        "\"\"\")\n",
        "\n",
        "# ì˜ˆì œ 2-1: ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°\n",
        "print(\"\\n[ì‹¤ìŠµ 2-1] ë‹¨ì–´ ì‚¬ì´ì˜ ê±°ë¦¬ ê³„ì‚°í•˜ê¸°\")\n",
        "\n",
        "def euclidean_distance(vec1, vec2):\n",
        "    \"\"\"ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚° (ë‘ ì  ì‚¬ì´ì˜ ê±°ë¦¬)\"\"\"\n",
        "    vec1 = np.array(vec1)\n",
        "    vec2 = np.array(vec2)\n",
        "    return np.sqrt(np.sum((vec1 - vec2)**2))\n",
        "\n",
        "# ê±°ë¦¬ ê³„ì‚° ì˜ˆì‹œ\n",
        "print(\"\\n'ìˆ˜í•™'ê³¼ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ ì‚¬ì´ì˜ ê±°ë¦¬:\")\n",
        "math_vector = words['ìˆ˜í•™']\n",
        "\n",
        "distances = {}\n",
        "for word, vector in words.items():\n",
        "    if word != 'ìˆ˜í•™':\n",
        "        dist = euclidean_distance(math_vector, vector)\n",
        "        distances[word] = dist\n",
        "        print(f\"  ìˆ˜í•™ â†” {word}: {dist:.2f}\")\n",
        "\n",
        "# ê°€ì¥ ê°€ê¹Œìš´ ë‹¨ì–´ ì°¾ê¸°\n",
        "closest = min(distances, key=distances.get)\n",
        "farthest = max(distances, key=distances.get)\n",
        "\n",
        "print(f\"\\nâœ… 'ìˆ˜í•™'ê³¼ ê°€ì¥ ë¹„ìŠ·í•œ ë‹¨ì–´: {closest} (ê±°ë¦¬: {distances[closest]:.2f})\")\n",
        "print(f\"âŒ 'ìˆ˜í•™'ê³¼ ê°€ì¥ ë‹¤ë¥¸ ë‹¨ì–´: {farthest} (ê±°ë¦¬: {distances[farthest]:.2f})\")\n",
        "\n",
        "# ì˜ˆì œ 2-2: ê±°ë¦¬ ì‹œê°í™”\n",
        "print(\"\\n[ì‹¤ìŠµ 2-2] ê±°ë¦¬ ì‹œê°í™”\")\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "\n",
        "# ëª¨ë“  ë‹¨ì–´ í‘œì‹œ\n",
        "for word, vector in words.items():\n",
        "    x, y = vector\n",
        "    plt.scatter(x, y, s=200, alpha=0.6)\n",
        "    plt.annotate(word, (x, y), fontsize=12, ha='center', va='bottom')\n",
        "\n",
        "# ìˆ˜í•™ì—ì„œ ê°€ì¥ ê°€ê¹Œìš´/ë¨¼ ë‹¨ì–´ë¡œ ì„  ê·¸ë¦¬ê¸°\n",
        "math_x, math_y = words['ìˆ˜í•™']\n",
        "closest_x, closest_y = words[closest]\n",
        "farthest_x, farthest_y = words[farthest]\n",
        "\n",
        "plt.plot([math_x, closest_x], [math_y, closest_y],\n",
        "         'g--', linewidth=2, label=f'ê°€ê¹Œì›€: {distances[closest]:.2f}')\n",
        "plt.plot([math_x, farthest_x], [math_y, farthest_y],\n",
        "         'r--', linewidth=2, label=f'ë©€ìŒ: {distances[farthest]:.2f}')\n",
        "\n",
        "plt.xlabel('í•™ì—… ê´€ë ¨ë„', fontsize=12)\n",
        "plt.ylabel('ì¹œêµ¬/ì‚¬íšŒì„± ê´€ë ¨ë„', fontsize=12)\n",
        "plt.title('ë‹¨ì–´ ì‚¬ì´ì˜ ê±°ë¦¬', fontsize=14, fontweight='bold')\n",
        "plt.legend(fontsize=10)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.xlim(0, 12)\n",
        "plt.ylim(0, 12)\n",
        "plt.tight_layout()\n",
        "plt.savefig('word_distances.png', dpi=300, bbox_inches='tight')\n",
        "print(\"âœ… ê·¸ë˜í”„ ì €ì¥: word_distances.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "JNe_URv8cVL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ì£¼ì œ 3: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ (ê°ë„ë¡œ ìœ ì‚¬ì„± ì¸¡ì •)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“ ì£¼ì œ 3: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ - ê°ë„ë¡œ ë¹„êµí•˜ê¸°\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\"\"\n",
        "ğŸ’¡ ê°œë…:\n",
        "ë‘ ë²¡í„° ì‚¬ì´ì˜ 'ê°ë„'ë¡œ ìœ ì‚¬ì„±ì„ ì¸¡ì •í•´ìš”!\n",
        "ê±°ë¦¬ ëŒ€ì‹  ë°©í–¥ì„ ë¹„êµí•˜ëŠ” ê±°ì˜ˆìš”.\n",
        "\n",
        "ì½”ì‚¬ì¸ ìœ ì‚¬ë„ = cos(Î¸)\n",
        "- ê°™ì€ ë°©í–¥ (Î¸=0Â°): cos(0Â°) = 1.0  â†’ ì™„ì „íˆ ê°™ìŒ!\n",
        "- ìˆ˜ì§ (Î¸=90Â°): cos(90Â°) = 0.0  â†’ ê´€ë ¨ ì—†ìŒ\n",
        "- ë°˜ëŒ€ ë°©í–¥ (Î¸=180Â°): cos(180Â°) = -1.0  â†’ ì™„ì „ ë°˜ëŒ€!\n",
        "\n",
        "ì™œ ê°ë„ë¥¼ ì“¸ê¹Œ?\n",
        "ì˜ˆ) \"ì¢‹ë‹¤\" = [1, 1], \"ì•„ì£¼ ì¢‹ë‹¤\" = [10, 10]\n",
        "    ê±°ë¦¬ëŠ” ë©€ì§€ë§Œ, ë°©í–¥(ì˜ë¯¸)ì€ ë˜‘ê°™ì•„ìš”!\n",
        "\"\"\")\n",
        "\n",
        "# ì˜ˆì œ 3-1: ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
        "print(\"\\n[ì‹¤ìŠµ 3-1] ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°í•˜ê¸°\")\n",
        "\n",
        "def cosine_sim(vec1, vec2):\n",
        "    \"\"\"ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\"\"\"\n",
        "    vec1 = np.array(vec1)\n",
        "    vec2 = np.array(vec2)\n",
        "    dot_product = np.dot(vec1, vec2)\n",
        "    norm1 = np.linalg.norm(vec1)\n",
        "    norm2 = np.linalg.norm(vec2)\n",
        "    return dot_product / (norm1 * norm2)\n",
        "\n",
        "print(\"\\n'ìˆ˜í•™'ê³¼ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„:\")\n",
        "print(\"(1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë¹„ìŠ·í•œ ì˜ë¯¸)\")\n",
        "\n",
        "similarities = {}\n",
        "for word, vector in words.items():\n",
        "    if word != 'ìˆ˜í•™':\n",
        "        sim = cosine_sim(math_vector, vector)\n",
        "        similarities[word] = sim\n",
        "        # ê°ë„ ê³„ì‚°\n",
        "        angle = np.arccos(sim) * 180 / np.pi\n",
        "        print(f\"  ìˆ˜í•™ â†” {word}: {sim:.3f} (ê°ë„: {angle:.1f}Â°)\")\n",
        "\n",
        "most_similar = max(similarities, key=similarities.get)\n",
        "least_similar = min(similarities, key=similarities.get)\n",
        "\n",
        "print(f\"\\nâœ… 'ìˆ˜í•™'ê³¼ ê°€ì¥ ìœ ì‚¬: {most_similar} ({similarities[most_similar]:.3f})\")\n",
        "print(f\"âŒ 'ìˆ˜í•™'ê³¼ ê°€ì¥ ë‹¤ë¦„: {least_similar} ({similarities[least_similar]:.3f})\")\n",
        "\n",
        "# ì˜ˆì œ 3-2: ê±°ë¦¬ vs ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ë¹„êµ\n",
        "print(\"\\n[ì‹¤ìŠµ 3-2] í¬ê¸°ê°€ ë‹¤ë¥¸ ë²¡í„° ë¹„êµ\")\n",
        "\n",
        "# ê°™ì€ ë°©í–¥, ë‹¤ë¥¸ í¬ê¸°ì˜ ë²¡í„°\n",
        "vec_small = [2, 1]   # \"ì¢‹ë‹¤\"\n",
        "vec_large = [8, 4]   # \"ë§¤ìš° ì¢‹ë‹¤\"\n",
        "\n",
        "dist = euclidean_distance(vec_small, vec_large)\n",
        "similarity = cosine_sim(vec_small, vec_large)\n",
        "\n",
        "print(f\"\\n[2, 1]ê³¼ [8, 4] ë¹„êµ:\")\n",
        "print(f\"  ìœ í´ë¦¬ë“œ ê±°ë¦¬: {dist:.2f} (ë©€ë‹¤ê³  íŒë‹¨)\")\n",
        "print(f\"  ì½”ì‚¬ì¸ ìœ ì‚¬ë„: {similarity:.3f} (ì™„ì „íˆ ê°™ì€ ë°©í–¥!)\")\n",
        "print(f\"\\nğŸ’¡ í•´ì„: í¬ê¸°ëŠ” ë‹¤ë¥´ì§€ë§Œ 'ë°©í–¥(ì˜ë¯¸)'ì€ ì™„ì „íˆ ê°™ì•„ìš”!\")"
      ],
      "metadata": {
        "id": "IokpFXizcckr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ì£¼ì œ 4: ë‹¨ì–´ ë²¡í„° ì—°ì‚° (ë²¡í„° ë§ì…ˆê³¼ ëº„ì…ˆ)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"â• ì£¼ì œ 4: ë‹¨ì–´ ë²¡í„° ì—°ì‚° - ì˜ë¯¸ì˜ ìˆ˜í•™!\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\"\"\n",
        "ğŸ’¡ ê°œë…:\n",
        "ë²¡í„°ë¼ë¦¬ ë”í•˜ê³  ë¹¼ë©´ ì˜ë¯¸ë„ ê³„ì‚°ë¼ìš”!\n",
        "\n",
        "ìœ ëª…í•œ ì˜ˆì‹œ:\n",
        "ì™• - ë‚¨ì + ì—¬ì = ì—¬ì™•\n",
        "íŒŒë¦¬ - í”„ë‘ìŠ¤ + í•œêµ­ = ì„œìš¸\n",
        "\n",
        "í•™êµ ì˜ˆì‹œ:\n",
        "ìˆ˜í•™ - í•™ì—… + ì¹œêµ¬ê´€ê³„ = ì²´ìœ¡?\n",
        "\"\"\")\n",
        "\n",
        "# ì˜ˆì œ 4-1: ë²¡í„° ì—°ì‚°\n",
        "print(\"\\n[ì‹¤ìŠµ 4-1] ë‹¨ì–´ ë²¡í„° ì—°ì‚°í•˜ê¸°\")\n",
        "\n",
        "# ìƒˆë¡œìš´ ë‹¨ì–´ ë²¡í„° ë§Œë“¤ê¸°\n",
        "print(\"\\nì›ë˜ ë‹¨ì–´ë“¤:\")\n",
        "print(f\"  ìˆ˜í•™: {words['ìˆ˜í•™']}\")\n",
        "print(f\"  ì²´ìœ¡: {words['ì²´ìœ¡']}\")\n",
        "\n",
        "# ìˆ˜í•™ + ì²´ìœ¡ = ?\n",
        "result = np.array(words['ìˆ˜í•™']) + np.array(words['ì²´ìœ¡'])\n",
        "print(f\"\\nìˆ˜í•™ + ì²´ìœ¡ = {result.tolist()}\")\n",
        "print(\"  â†’ í•™ì—…ë„ í•˜ê³  ìš´ë™ë„ í•˜ëŠ”... 'ì²´ìœ¡ëŒ€íšŒ'?\")\n",
        "\n",
        "# ì²´ìœ¡ - ì¹œêµ¬ê´€ê³„ = ?\n",
        "# ì²´ìœ¡ [3, 10]ì—ì„œ ì¹œêµ¬ê´€ê³„ë¥¼ ì¤„ì´ë©´\n",
        "result2 = np.array(words['ì²´ìœ¡']) - np.array([0, 5])\n",
        "print(f\"\\nì²´ìœ¡ - [ì¹œêµ¬ê´€ê³„ ë§ì´] = {result2.tolist()}\")\n",
        "print(\"  â†’ í˜¼ì í•˜ëŠ” ìš´ë™, 'í—¬ìŠ¤'?\")\n",
        "\n",
        "# ì˜ˆì œ 4-2: ë‹¨ì–´ ìœ ì¶” (Word Analogy)\n",
        "print(\"\\n[ì‹¤ìŠµ 4-2] ë‹¨ì–´ ìœ ì¶” ê²Œì„\")\n",
        "print(\"\\në¬¸ì œ: 'ìˆ˜í•™'ì€ 'ì‹œí—˜'ê³¼ ê´€ê³„ê°€ ìˆë“¯ì´, 'ì²´ìœ¡'ì€ ë¬´ì—‡ê³¼ ê´€ê³„ê°€ ìˆì„ê¹Œ?\")\n",
        "print(\"ì‹: ìˆ˜í•™ - ì‹œí—˜ + ì²´ìœ¡ = ?\")\n",
        "\n",
        "vec_math = np.array(words['ìˆ˜í•™'])\n",
        "vec_test = np.array(words['ì‹œí—˜'])\n",
        "vec_pe = np.array(words['ì²´ìœ¡'])\n",
        "\n",
        "result_vec = vec_math - vec_test + vec_pe\n",
        "print(f\"\\nê³„ì‚° ê²°ê³¼ ë²¡í„°: {result_vec}\")\n",
        "\n",
        "# ê°€ì¥ ê°€ê¹Œìš´ ë‹¨ì–´ ì°¾ê¸°\n",
        "print(\"\\nê° ë‹¨ì–´ì™€ì˜ ê±°ë¦¬:\")\n",
        "min_dist = float('inf')\n",
        "answer = None\n",
        "\n",
        "for word, vector in words.items():\n",
        "    if word not in ['ìˆ˜í•™', 'ì‹œí—˜', 'ì²´ìœ¡']:\n",
        "        dist = euclidean_distance(result_vec, vector)\n",
        "        print(f\"  {word}: {dist:.2f}\")\n",
        "        if dist < min_dist:\n",
        "            min_dist = dist\n",
        "            answer = word\n",
        "\n",
        "print(f\"\\nâœ… ì •ë‹µ: {answer}!\")"
      ],
      "metadata": {
        "id": "CmgsdzYrceLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ì£¼ì œ 5: ë¬¸ì¥ ë²¡í„°í™” (Bag of Words)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ“ ì£¼ì œ 5: ë¬¸ì¥ì„ ë²¡í„°ë¡œ ë§Œë“¤ê¸°\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\"\"\n",
        "ğŸ’¡ ê°œë…:\n",
        "ë¬¸ì¥ ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ë²¡í„°ë¡œ í‘œí˜„í•  ìˆ˜ ìˆì–´ìš”!\n",
        "ë‹¨ì–´ ì£¼ë¨¸ë‹ˆ(Bag of Words) ë°©ë²•: ê° ë‹¨ì–´ê°€ ëª‡ ë²ˆ ë‚˜ì™”ëŠ”ì§€ ì„¸ê¸°\n",
        "\n",
        "ì˜ˆì‹œ ë¬¸ì¥: \"ë‚˜ëŠ” ìˆ˜í•™ì„ ì¢‹ì•„í•˜ê³  ê³¼í•™ë„ ì¢‹ì•„í•œë‹¤\"\n",
        "ë‹¨ì–´ ìˆœì„œ: [ë‚˜, ëŠ”, ìˆ˜í•™, ì„, ì¢‹ì•„í•˜, ê³ , ê³¼í•™, ë„, í•œë‹¤]\n",
        "ë²¡í„°: ê° ë‹¨ì–´ ë“±ì¥ íšŸìˆ˜\n",
        "\"\"\")\n",
        "\n",
        "# ì˜ˆì œ 5-1: ê°„ë‹¨í•œ Bag of Words\n",
        "print(\"\\n[ì‹¤ìŠµ 5-1] ë¬¸ì¥ì„ ë²¡í„°ë¡œ ë³€í™˜í•˜ê¸°\")\n",
        "\n",
        "# ì„¸ ê°œì˜ í•™êµ ê´€ë ¨ ë¬¸ì¥\n",
        "sentences = [\n",
        "    \"ìˆ˜í•™ ì‹œí—˜ ê³µë¶€\",\n",
        "    \"ì²´ìœ¡ ì‹œê°„ ì¹œêµ¬\",\n",
        "    \"ìˆ˜í•™ ì²´ìœ¡ ê³µë¶€\"\n",
        "]\n",
        "\n",
        "# ì „ì²´ ë‹¨ì–´ ì‚¬ì „ ë§Œë“¤ê¸°\n",
        "all_words = []\n",
        "for sentence in sentences:\n",
        "    all_words.extend(sentence.split())\n",
        "vocabulary = sorted(set(all_words))\n",
        "\n",
        "print(f\"\\në‹¨ì–´ ì‚¬ì „: {vocabulary}\")\n",
        "print(f\"(ì´ {len(vocabulary)}ê°œ ë‹¨ì–´)\")\n",
        "\n",
        "# ê° ë¬¸ì¥ì„ ë²¡í„°ë¡œ ë³€í™˜\n",
        "print(\"\\nê° ë¬¸ì¥ì˜ ë²¡í„° í‘œí˜„:\")\n",
        "sentence_vectors = []\n",
        "\n",
        "for i, sentence in enumerate(sentences):\n",
        "    words_in_sentence = sentence.split()\n",
        "    vector = [words_in_sentence.count(word) for word in vocabulary]\n",
        "    sentence_vectors.append(vector)\n",
        "    print(f\"\\në¬¸ì¥ {i+1}: '{sentence}'\")\n",
        "    print(f\"  ë²¡í„°: {vector}\")\n",
        "    print(f\"  ì˜ë¯¸: \", end=\"\")\n",
        "    for j, word in enumerate(vocabulary):\n",
        "        if vector[j] > 0:\n",
        "            print(f\"{word}({vector[j]}ë²ˆ) \", end=\"\")\n",
        "    print()\n",
        "\n",
        "# ì˜ˆì œ 5-2: ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ ë¹„êµ\n",
        "print(\"\\n[ì‹¤ìŠµ 5-2] ë¬¸ì¥ ê°„ ìœ ì‚¬ë„ ê³„ì‚°\")\n",
        "\n",
        "print(\"\\në¬¸ì¥ 1ê³¼ ë‹¤ë¥¸ ë¬¸ì¥ë“¤ì˜ ìœ ì‚¬ë„:\")\n",
        "for i in range(1, len(sentences)):\n",
        "    similarity = cosine_sim(sentence_vectors[0], sentence_vectors[i])\n",
        "    print(f\"  ë¬¸ì¥ 1 â†” ë¬¸ì¥ {i+1}: {similarity:.3f}\")\n",
        "\n",
        "print(\"\\nğŸ’¡ í•´ì„:\")\n",
        "print(\"  - 'ìˆ˜í•™'ì´ë¼ëŠ” ê³µí†µ ë‹¨ì–´ê°€ ìˆìœ¼ë©´ ìœ ì‚¬ë„ê°€ ë†’ì•„ìš”\")\n",
        "print(\"  - ê°™ì€ ë‹¨ì–´ê°€ ë§ì„ìˆ˜ë¡ ë²¡í„°ê°€ ë¹„ìŠ·í•´ì ¸ìš”\")"
      ],
      "metadata": {
        "id": "B4yvttN7ckA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ì£¼ì œ 6: TF-IDF (ì¤‘ìš”í•œ ë‹¨ì–´ ì°¾ê¸°)\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"â­ ì£¼ì œ 6: ì¤‘ìš”í•œ ë‹¨ì–´ ì°¾ê¸° (TF-IDF)\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\"\"\n",
        "ğŸ’¡ ê°œë…:\n",
        "ëª¨ë“  ë‹¨ì–´ê°€ ë˜‘ê°™ì´ ì¤‘ìš”í•œ ê±´ ì•„ë‹ˆì—ìš”!\n",
        "\n",
        "TF (Term Frequency): ë¬¸ì„œì—ì„œ ë‹¨ì–´ê°€ ë‚˜ì˜¨ íšŸìˆ˜\n",
        "IDF (Inverse Document Frequency): í¬ê·€í•œ ë‹¨ì–´ì¼ìˆ˜ë¡ ì¤‘ìš”\n",
        "\n",
        "ì˜ˆì‹œ:\n",
        "- \"ì´\", \"ê·¸\", \"ì €\" â†’ ìì£¼ ë‚˜ì˜¤ì§€ë§Œ ì¤‘ìš”í•˜ì§€ ì•ŠìŒ (ë‚®ì€ ì ìˆ˜)\n",
        "- \"ì–‘ìì—­í•™\", \"ë¯¸ì ë¶„\" â†’ ì ê²Œ ë‚˜ì˜¤ì§€ë§Œ ì¤‘ìš”í•¨ (ë†’ì€ ì ìˆ˜)\n",
        "\n",
        "TF-IDF = TF Ã— IDF\n",
        "\"\"\")\n",
        "\n",
        "# ì˜ˆì œ 6-1: TF-IDF ê³„ì‚°\n",
        "print(\"\\n[ì‹¤ìŠµ 6-1] TF-IDFë¡œ ì¤‘ìš”í•œ ë‹¨ì–´ ì°¾ê¸°\")\n",
        "\n",
        "# í•™êµ ê´€ë ¨ ë¬¸ì„œë“¤\n",
        "documents = [\n",
        "    \"ìˆ˜í•™ì€ ë…¼ë¦¬ì  ì‚¬ê³ ë¥¼ í‚¤ì›Œìš”\",\n",
        "    \"ì²´ìœ¡ì€ ê±´ê°•ê³¼ ì²´ë ¥ì„ í‚¤ì›Œìš”\",\n",
        "    \"ìŒì•…ì€ ê°ì„±ê³¼ ì°½ì˜ë ¥ì„ í‚¤ì›Œìš”\",\n",
        "    \"ìˆ˜í•™ê³¼ ê³¼í•™ì€ ë…¼ë¦¬ì  ì‚¬ê³ ê°€ ì¤‘ìš”í•´ìš”\"\n",
        "]\n",
        "\n",
        "print(\"\\në¬¸ì„œë“¤:\")\n",
        "for i, doc in enumerate(documents):\n",
        "    print(f\"  ë¬¸ì„œ {i+1}: {doc}\")\n",
        "\n",
        "# ê°„ë‹¨í•œ TF-IDF ê³„ì‚° (ì‹¤ì œë¡œëŠ” sklearn ì‚¬ìš©)\n",
        "def simple_tfidf(documents):\n",
        "    \"\"\"ê°„ë‹¨í•œ TF-IDF ê³„ì‚°\"\"\"\n",
        "    # 1. ëª¨ë“  ë‹¨ì–´ ìˆ˜ì§‘\n",
        "    all_words = set()\n",
        "    for doc in documents:\n",
        "        words = doc.replace('ì€', '').replace('ì„', '').replace('ì™€', '').replace('ê°€', '').split()\n",
        "        all_words.update(words)\n",
        "\n",
        "    # 2. TF ê³„ì‚° (ë¬¸ì„œì—ì„œ ë‹¨ì–´ ë¹ˆë„)\n",
        "    tf_scores = []\n",
        "    for doc in documents:\n",
        "        words = doc.replace('ì€', '').replace('ì„', '').replace('ì™€', '').replace('ê°€', '').split()\n",
        "        tf = {}\n",
        "        for word in all_words:\n",
        "            tf[word] = words.count(word)\n",
        "        tf_scores.append(tf)\n",
        "\n",
        "    # 3. IDF ê³„ì‚° (ì „ì²´ ë¬¸ì„œì—ì„œ ë“±ì¥ íšŸìˆ˜ì˜ ì—­ìˆ˜)\n",
        "    idf_scores = {}\n",
        "    num_docs = len(documents)\n",
        "    for word in all_words:\n",
        "        doc_count = sum(1 for doc in documents if word in doc)\n",
        "        idf_scores[word] = np.log(num_docs / (1 + doc_count))\n",
        "\n",
        "    # 4. TF-IDF ê³„ì‚°\n",
        "    tfidf_scores = []\n",
        "    for tf in tf_scores:\n",
        "        tfidf = {}\n",
        "        for word in all_words:\n",
        "            tfidf[word] = tf[word] * idf_scores[word]\n",
        "        tfidf_scores.append(tfidf)\n",
        "\n",
        "    return tfidf_scores, idf_scores\n",
        "\n",
        "tfidf_scores, idf_scores = simple_tfidf(documents)\n",
        "\n",
        "# ê° ë¬¸ì„œì˜ ì¤‘ìš” ë‹¨ì–´ ì¶œë ¥\n",
        "print(\"\\nê° ë¬¸ì„œì˜ ì¤‘ìš” ë‹¨ì–´ (TF-IDF ì ìˆ˜):\")\n",
        "for i, tfidf in enumerate(tfidf_scores):\n",
        "    print(f\"\\në¬¸ì„œ {i+1}: {documents[i]}\")\n",
        "    # ì ìˆ˜ê°€ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬\n",
        "    sorted_words = sorted(tfidf.items(), key=lambda x: x[1], reverse=True)\n",
        "    print(\"  ì¤‘ìš” ë‹¨ì–´:\")\n",
        "    for word, score in sorted_words[:3]:  # ìƒìœ„ 3ê°œë§Œ\n",
        "        if score > 0:\n",
        "            print(f\"    {word}: {score:.3f}\")\n",
        "\n",
        "print(\"\\nğŸ’¡ í•´ì„:\")\n",
        "print(\"  - 'í‚¤ì›Œìš”'ëŠ” ëª¨ë“  ë¬¸ì„œì— ë‚˜ì™€ì„œ ì ìˆ˜ê°€ ë‚®ì•„ìš” (ì¼ë°˜ì )\")\n",
        "print(\"  - 'ìˆ˜í•™', 'ì²´ìœ¡', 'ìŒì•…'ì€ íŠ¹ì • ë¬¸ì„œì—ë§Œ ë‚˜ì™€ì„œ ì ìˆ˜ê°€ ë†’ì•„ìš” (íŠ¹ë³„í•¨)\")"
      ],
      "metadata": {
        "id": "v3dG1sz3cnlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================================\n",
        "# ì¢…í•© ì‹¤ìŠµ: ì˜í™” ë¦¬ë·° ë¶„ì„\n",
        "# ============================================================================\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ğŸ¬ ì¢…í•© ì‹¤ìŠµ: ì˜í™” ë¦¬ë·° ìœ ì‚¬ë„ ë¶„ì„\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\"\"\n",
        "ğŸ’¡ ì‹¤ì „ ì ìš©:\n",
        "ì‹¤ì œ ì˜í™” ë¦¬ë·°ë¥¼ ë²¡í„°ë¡œ ë°”ê¿”ì„œ ë¹„ìŠ·í•œ ë¦¬ë·°ë¥¼ ì°¾ì•„ë´ìš”!\n",
        "\"\"\")\n",
        "\n",
        "# ì˜ˆì œ: ì˜í™” ë¦¬ë·°ë“¤\n",
        "reviews = {\n",
        "    \"ë¦¬ë·°A\": \"ì¬ë¯¸ìˆê³  ê°ë™ì ì¸ ì˜í™”\",\n",
        "    \"ë¦¬ë·°B\": \"ì§€ë£¨í•˜ê³  ì¬ë¯¸ì—†ëŠ” ì˜í™”\",\n",
        "    \"ë¦¬ë·°C\": \"ê°ë™ì ì´ê³  ëˆˆë¬¼ë‚˜ëŠ” ì˜í™”\",\n",
        "    \"ë¦¬ë·°D\": \"ì•¡ì…˜ì´ ë§ê³  ì¬ë¯¸ìˆëŠ” ì˜í™”\",\n",
        "    \"ë¦¬ë·°E\": \"ì§€ë£¨í•˜ê³  ì¡¸ë¦° ì˜í™”\"\n",
        "}\n",
        "\n",
        "print(\"\\nì˜í™” ë¦¬ë·°ë“¤:\")\n",
        "for name, review in reviews.items():\n",
        "    print(f\"  {name}: {review}\")\n",
        "\n",
        "# ë‹¨ì–´ ì‚¬ì „ ë§Œë“¤ê¸°\n",
        "all_review_words = []\n",
        "for review in reviews.values():\n",
        "    all_review_words.extend(review.split())\n",
        "review_vocab = sorted(set(all_review_words))\n",
        "\n",
        "print(f\"\\në‹¨ì–´ ì‚¬ì „: {review_vocab}\")\n",
        "\n",
        "# ë¦¬ë·°ë¥¼ ë²¡í„°ë¡œ ë³€í™˜\n",
        "print(\"\\nê° ë¦¬ë·°ì˜ ë²¡í„°:\")\n",
        "review_vectors = {}\n",
        "for name, review in reviews.items():\n",
        "    words = review.split()\n",
        "    vector = [words.count(word) for word in review_vocab]\n",
        "    review_vectors[name] = vector\n",
        "    print(f\"  {name}: {vector}\")\n",
        "\n",
        "# ë¦¬ë·°Aì™€ ë‹¤ë¥¸ ë¦¬ë·°ë“¤ì˜ ìœ ì‚¬ë„\n",
        "print(\"\\në¦¬ë·°Aì™€ ë‹¤ë¥¸ ë¦¬ë·°ë“¤ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„:\")\n",
        "base_review = \"ë¦¬ë·°A\"\n",
        "similarities = {}\n",
        "\n",
        "for name, vector in review_vectors.items():\n",
        "    if name != base_review:\n",
        "        sim = cosine_sim(review_vectors[base_review], vector)\n",
        "        similarities[name] = sim\n",
        "        print(f\"  {base_review} â†” {name}: {sim:.3f}\")\n",
        "\n",
        "# ê°€ì¥ ë¹„ìŠ·í•œ ë¦¬ë·° ì°¾ê¸°\n",
        "most_similar_review = max(similarities, key=similarities.get)\n",
        "least_similar_review = min(similarities, key=similarities.get)\n",
        "\n",
        "print(f\"\\nâœ… '{reviews[base_review]}'ì™€ ê°€ì¥ ë¹„ìŠ·í•œ ë¦¬ë·°:\")\n",
        "print(f\"   {most_similar_review}: '{reviews[most_similar_review]}' (ìœ ì‚¬ë„: {similarities[most_similar_review]:.3f})\")\n",
        "\n",
        "print(f\"\\nâŒ '{reviews[base_review]}'ì™€ ê°€ì¥ ë‹¤ë¥¸ ë¦¬ë·°:\")\n",
        "print(f\"   {least_similar_review}: '{reviews[least_similar_review]}' (ìœ ì‚¬ë„: {similarities[least_similar_review]:.3f})\")\n",
        "\n",
        "# ìœ ì‚¬ë„ í–‰ë ¬ ì‹œê°í™”\n",
        "print(\"\\n[ì‹œê°í™”] ë¦¬ë·° ê°„ ìœ ì‚¬ë„ íˆíŠ¸ë§µ\")\n",
        "\n",
        "review_names = list(reviews.keys())\n",
        "n = len(review_names)\n",
        "similarity_matrix = np.zeros((n, n))\n",
        "\n",
        "for i, name1 in enumerate(review_names):\n",
        "    for j, name2 in enumerate(review_names):\n",
        "        if i == j:\n",
        "            similarity_matrix[i][j] = 1.0\n",
        "        else:\n",
        "            similarity_matrix[i][j] = cosine_sim(review_vectors[name1], review_vectors[name2])\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(similarity_matrix, cmap='YlOrRd', aspect='auto')\n",
        "plt.colorbar(label='Cosine Similarity')\n",
        "plt.xticks(range(n), review_names)\n",
        "plt.yticks(range(n), review_names)\n",
        "plt.title('Movie Review Similarity Heatmap', fontsize=14, fontweight='bold')\n",
        "\n",
        "# ê° ì…€ì— ìœ ì‚¬ë„ ê°’ í‘œì‹œ\n",
        "for i in range(n):\n",
        "    for j in range(n):\n",
        "        plt.text(j, i, f'{similarity_matrix[i][j]:.2f}',\n",
        "                ha='center', va='center', color='black' if similarity_matrix[i][j] < 0.5 else 'white')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('review_similarity.png', dpi=300, bbox_inches='tight')\n",
        "print(\"âœ… ê·¸ë˜í”„ ì €ì¥: review_similarity.png\")\n",
        "plt.close()"
      ],
      "metadata": {
        "id": "BMM3eiaMc5cX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}